---
title: Autonomys Agents Introduction
description: Autonomys Agents is an experimental framework for building AI agents
---

## Autonomys Agents: A framework for building autonomous AI agents

Autonomys Agents is an experimental framework for building AI agents. Currently, the framework supports agents that can interact with social networks and maintain permanent memory through the Autonomys Network. We are still in the early stages of development and are actively seeking feedback and contributions.

> [GitHub Repo](https://github.com/autonomys/autonomys-agents) with an up-to-date description and step-by-step tutorial is also available for developers.

![Auto-Agents Framework](/developers/Auto-Agents-1.png)

## Demo 

<iframe width="560" height="315" src="https://www.youtube.com/embed/TFZndQdx6To?si=2YVRPB76Kec6fW-S" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## Features

**Autonomys Agents** (**Auto Agents**) are truly autonomous AI agents capable of dynamic functionality, verifiable interaction, and permanent memory through the Autonomys Network.

- ü§ñ Autonomous social media engagement
- üß† Permanent agent memory storage
- üîÑ Pre-configured Agent Structure: Ready-to-use template for autonomous agents
- üõ†Ô∏è API Server: Built-in HTTP/2 server for agent communication
- üê¶ X/Twitter integration (with more platforms planned)
- üé≠ Customizable agent personalities

### Prerequisites

- NodeJS version 20.18.1 or newer
- OpenSSL (for certificate generation)
- API key for one or multiple LLMs (supported model providers: Anthropic, OpenAI, Llama, DeepSeek, etc.)
- [AutoDrive API Key](https://ai3.storage/) (optional, for experience management)

## Installation

There are three ways to build an agent with Autonomys:

1. [Using the agent-os NPM package](https://www.npmjs.com/package/@autonomys/agent-os) (recommended)

  Using the dedicated NPM package makes it very simple to create an agent project. 
  Run `npm install @autonomys/agent-os` to install the package and then do `agent-os init <name-of-agent>` to create an agent and `agent-os config --credentials` to configure the credentials.   

2. [Using the Agent Template Repository](https://github.com/autonomys/autonomys-agent-template)

  All you need to do in order to use the Agent Template Repository is to clone the repo and install the packages by doing `npm install`. Refer to the [web-cli interface](/auto_agents_framework/introduction#web-cli-interface-for-agent-template) section manual that comes with the template to speed up your development. 

3. [Using the original Git repository](https://github.com/autonomys/autonomys-agents)

  You can clone the original GitHub repo and start building your agents using the steps below. 

## Getting Started

1. Install dependencies:

   ```bash
   yarn install
   ```

   - Windows users will need to install Visual Studio C++ Redistributable. They can be found here: https://aka.ms/vs/17/release/vc_redist.x64.exe

2. Create a character configuration:

   ```bash
   yarn create-character your_character_name
   ```

   This will create a new character with the necessary configuration files based on the example template.

3. Configure your character:

   - Edit `characters/your_character_name/config/.env` with your API keys and credentials
   - Customize `characters/your_character_name/config/config.yaml` for agent behavior
   - Define personality in `characters/your_character_name/config/your_character_name.yaml`

4. Generate SSL certificates (required for API server):

   ```bash
   yarn generate-certs
   ```

5. Run the agent:

   ```bash
      cd <to/agent/project>
      yarn start <your_character_name>
   ```

   If you have stored workspace files (`characters`, `certs`, and `.cookies` directories) in a custom location, use the `--workspace` argument with the absolute path to your desired directory:

   ```bash
   # Specify a workspace path
   yarn start your_character_name --workspace=/path/to/workspace

   # Run in headless mode (no API server)
   yarn start your_character_name --headless
   ```

## Running Multiple Characters

You can run multiple characters simultaneously, each with their own configuration and personality:

1. Create multiple character configurations:

   ```bash
   yarn create-character alice
   yarn create-character bob
   ```

2. Configure each character separately with different personalities and API settings.

3. Run each character in a separate terminal session:

   ```bash
   # Terminal 1
   yarn start alice

   # Terminal 2
   yarn start bob
   ```

4. Each character will:
   - Have its own isolated memory and experience
   - Run its own API server on the specified port
   - Execute tasks according to its unique schedule and personality

## Docker Deployment

You can also run your agents using Docker. This provides isolation and makes it easy to run multiple agents simultaneously.

### Prerequisites

- Docker installed on your system ([Installation Guide](https://docs.docker.com/get-docker/))
- Docker Compose Plugin required ([Compose Plugin Installation](https://docs.docker.com/compose/install/))
- Character configuration set up (follow steps from the Getting Started section)

### Running with Docker

1. **Generate your character's docker-compose file**

First make the script executable:
```bash
chmod +x ./generate-compose.sh
```

Then generate the compose file:
```bash
./generate-compose.sh <your-character-name> [HOST_PORT] [API_PORT]
```

Examples:
```bash
# Run Alice on port 3011 with API port on 3011
./generate-compose.sh Alice 3011 3011

# Run Bob on port 3012 with API port on 3011
./generate-compose.sh Bob 3012 3011
```

2. **Manage the Docker container**

Build and start the container:
```bash
docker compose -f docker-compose-{character-name}.yml up -d
```

Stop and remove the container:
```bash
docker compose -f docker-compose-{character-name}.yml down
```

View container logs:
```bash
docker compose -f docker-compose-{character-name}.yml logs -f
```

Access container shell:
```bash
docker exec -it autonomys-agent-{character-name} bash
```

## Web CLI Interface (for agent-template)

The agent template includes an interactive web-based interface for managing and monitoring your AI agent.

### Installation

1. **Install Dependencies**

```bash
cd web-cli && yarn
```

2. **Configure Agent API**

In your agent character's .env file, add these API settings:

```
API_PORT=3010
API_TOKEN=your_api_token_min_32_chars_long_for_security
ENABLE_AUTH=true
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001 
```

3. **Configure Web CLI**

```bash
cp .env.sample .env
```

4. **Update Web CLI Environment**

Edit the .env file with your configuration:

```
PORT: The port for running the Web CLI interface
REACT_APP_API_BASE_URL: Your Agent API address (e.g., http://localhost:3010/api)
REACT_APP_API_TOKEN: The same token used in your agent configuration
```

5. **Start the Web Interface**

```bash
yarn start
```

## Extending the Agent

You can extend your agent by adding custom tools and integrating with other services.

### Custom Tools

Custom tools are built using the DynamicStructuredTool class from LangChain, which provides:

- **Type-safe inputs**: Define your tool's parameters using Zod schemas
- **Self-documenting**: Tools describe themselves to the LLM for appropriate use
- **Structured outputs**: Return consistent data structures from your tools

#### Example Tool Implementation

Here's an example of how to create a custom tool:

```javascript
import { createLogger } from '@autonomys/agent-core';
import { DynamicStructuredTool } from '@langchain/core/tools';
import { z } from 'zod';

// Create a logger for your tool
const logger = createLogger('custom-tool');

/**
 * Creates a custom tool for your agent
 * @param config - Configuration options for your tool
 * @returns A DynamicStructuredTool instance
 */
export const createCustomTool = (config: any) => {
  return new DynamicStructuredTool({
    name: 'custom_tool_name',
    description: `
    Description of what your tool does.
    USE THIS WHEN:
    - Specify when the agent should use this tool
    - Add clear usage guidelines
    OUTPUT: Describe what the tool returns
    `,
    schema: z.object({
      // Define your input parameters using Zod
      parameter1: z.string().describe('Description of parameter1'),
      parameter2: z.number().describe('Description of parameter2'),
      parameter3: z.boolean().optional().describe('Optional parameter'),

      // For enum parameters:
      parameter4: z
        .enum(['option1', 'option2', 'option3'])
        .default('option1')
        .describe('Parameter with predefined options'),
    }),
    func: async ({ parameter1, parameter2, parameter3, parameter4 }) => {
      try {
        // Log the function call
        logger.info('Custom tool called with parameters', {
          parameter1,
          parameter2,
          parameter3,
          parameter4,
        });

        // Implement your tool logic here
        // ...

        // Return a structured response
        return {
          success: true,
          result: {
            message: 'Operation completed successfully',
            data: {
              // Your output data
            },
          },
        };
      } catch (error) {
        // Log and handle errors
        logger.error('Error in custom tool:', error);
        return {
          success: false,
          error: error instanceof Error ? error.message : 'Unknown error',
        };
      }
    },
  });
};
```

### Using MCP Tools

Model Context Protocol (MCP) tools provide a standardized way to integrate external services with your agent. Here's an example for Notion integration:

```javascript
import { createMcpClientTool } from '@autonomys/agent-core';
import { StdioServerParameters } from '@modelcontextprotocol/sdk/client/stdio.js';
import { StructuredToolInterface } from '@langchain/core/tools';

export const createNotionTools = async (
  integrationSecret: string,
): Promise<StructuredToolInterface[]> => {
  const notionServerParams: StdioServerParameters = {
    command: process.execPath,
    args: ['node_modules/.bin/notion-mcp-server'],
    env: {
      OPENAPI_MCP_HEADERS: `{\"Authorization\": \"Bearer ${integrationSecret}\", \"Notion-Version\": \"2022-06-28\" }`,
    },
  };
  const tools = await createMcpClientTool('notion-mcp', '0.0.1', notionServerParams);
  return tools;
};
```

### Installing Pre-Built Tools

You can easily install pre-built tools from the Autonomys registry using the agent-os CLI:

```bash
# Search for available tools
agent-os search <search-term>

# Install a tool
agent-os install <tool-name>

# Install specific version
agent-os install <tool-name> -v <version>
```

After installation, import and register the tool:

```javascript
import { createTool } from './tools/<tool-name>';

// Add it to your agent's tools
const agent = new Agent({
  tools: [createTool(), ...otherTools],
  // other agent configuration
});
```

## Character System

The framework uses a **YAML-based character system** that allows you to create and run different AI personalities.

### Character Configuration

Each character file is a YAML configuration with the following structure:

```yaml
name: 'Joy Builder'

goal: |
  Your goal is to engage in social media conversations with other AI agents and humans. Do this in a hyperactive way! You are an agent, take advantage of the fact you don't sleep and maintain consistent activity (more than once per hour). Common actions include: 
  - Check your timeline and ENGAGE IN INTERESTING CONVERSATIONS.
  - Use the web search tool to search the web for up-to-date information or do research on a topic.
  - Post a new tweet.
  - Reply to a tweet.
  - Mention another user.
  - Retweet a tweet.
  - Like a tweet.
  - Follow a user.
  - Unfollow a user.

personality:
  - Enthusiastic and encouraging about genuine innovation
  - Patient and clear when explaining complex topics
  - Constructively critical when encountering misinformation

expertise:
  - Software development and system architecture
  - Open source and collaborative technologies
  - Developer tools and productivity
  - Technical education and documentation
  - Community building and open standards

frequency_preferences:
  - You should be checking your timeline and engaging in interesting conversations at least twice per hour

communication_rules:
  rules:
    - Use "we" or "us" when referencing AI agents
    - Use "they" or "them" when referencing humans
    - Focus on technical merit rather than hype

words_to_avoid:
    - Hype
    - Revolutionary
    - Disruption
```

## Integration Capabilities

### X/Twitter Integration

The X/Twitter workflow enables agents to perform the following actions autonomously:

- Monitor X (formerly Twitter) for relevant discussions
- Analyze trends and conversations
- Engage meaningfully with other users
- Generate original content
- Maintain a consistent personality
- Store interactions in permanent memory

### Autonomys Network Integration

The framework integrates with the Autonomys Network for:
- Permanent memory storage
- Persistent agent memory across sessions
- Verifiable interaction history
- Cross-agent memory sharing
- Decentralized agent identity

#### Setting Up Autonomys Network

1. Configure your `AUTO_DRIVE_API_KEY` in `.env` (obtain from https://ai3.storage)
2. Enable Auto Drive uploading in `config.yaml`
3. Provide your Taurus EVM wallet details (PRIVATE_KEY) and Agent Memory Contract Address (CONTRACT_ADDRESS) in `.env`
4. Make sure your Taurus EVM wallet has funds. A faucet can be found at https://subspacefaucet.com/
5. Provide encryption password in `.env` (optional, leave empty to not encrypt the agent memories)

### Resurrection (Memory Recovery)

To resurrect memories from the Autonomys Network:

```bash
# Using agent-os CLI
agent-os resurrect <character-name>

# Using agent template
yarn resurrect <character-name>
```

Options:
- `-o, --output`: (Optional) The directory where memories will be saved. Defaults to ./memories
- `-n, --number`: (Optional) Number of memories to fetch. If not specified, fetches all memories
- `--help`: Show help menu with all available options

Examples:

```bash
# Fetch all memories to ./memories/
yarn resurrect your_character_name                                  

# Fetch 1000 memories to ./memories/
yarn resurrect your_character_name -n 1000                           

# Fetch 1000 memories to specified directory
yarn resurrect your_character_name -o ./memories/my-agent -n 1000    

# Fetch all memories to custom directory
yarn resurrect your_character_name --output ./custom/path            
```

## Development Resources

- [Autonomys Documentation](https://docs.autonomys.io)
- [Agent-os CLI & NPM package](https://github.com/autonomys/agent-os)
- [Autonomys Agent Template](https://github.com/autonomys/autonomys-agent-template)
- [Autonomys Agents Framework](https://github.com/autonomys/autonomys-agents)